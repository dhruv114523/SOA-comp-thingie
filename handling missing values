import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer

# Load dataset
file_path = "data/srcsc-2025-dam-data-for-students.csv"
df = pd.read_csv(file_path)

# Define numerical and categorical columns (including "Region")
numerical_columns = ['Volume (m3)', 'Length (km)', 'Height (m)', 'Year Completed', 'Inspection Frequency']
categorical_columns = ['Region', 'Spillway', 'Hazard']
all_columns = numerical_columns + categorical_columns

df_clean = df.copy()

# Step 1: Treat numerical columns with 0 as missing values
for col in numerical_columns:
    df_clean.loc[df_clean[col] == 0, col] = None

# Step 2: Encode categorical columns before training
label_encoders = {}
for col in categorical_columns:
    df_clean[col] = df_clean[col].astype(str)  # Ensure all categorical data are strings
    le = LabelEncoder()
    df_clean[col] = le.fit_transform(df_clean[col])
    label_encoders[col] = le  # Save encoder for later use

# Step 3: Select only rows where ALL required columns (including Region) are filled
df_training_data = df_clean.dropna(subset=all_columns)

# Step 4: Train models only on the fully complete rows and use them to fill missing values
models = {}  # Dictionary to store trained models

for target in all_columns:
    # Select training data (only fully complete rows)
    X_train = df_training_data[numerical_columns + ['Region']]  # Include "Region" in training
    y_train = df_training_data[target]

    # Select test data (rows with missing target column)
    df_missing = df_clean[df_clean[target].isnull()]
    X_test = df_missing[numerical_columns + ['Region']]

    if not df_missing.empty:
        # Train appropriate model
        if target in numerical_columns:
            model = RandomForestRegressor(n_estimators=100, random_state=42)
        else:
            model = LogisticRegression(max_iter=200)

        # Ensure X_train has no NaNs
        if X_train.isnull().sum().sum() > 0:
            X_train = X_train.fillna(X_train.median())

        model.fit(X_train, y_train)

        # Save trained model for later use
        models[target] = model

        # Ensure X_test has no NaNs before predicting
        if X_test.isnull().sum().sum() > 0:
            X_test = X_test.fillna(X_train.median())

        # Predict missing values
        y_pred = model.predict(X_test)

        # Fill missing values
        missing_indices = df_missing.index
        if len(missing_indices) == len(y_pred):  # Ensure proper alignment
            df_clean.loc[missing_indices, target] = y_pred

# Step 5: Decode categorical values back to original labels
for col, le in label_encoders.items():
    df_clean[col] = le.inverse_transform(df_clean[col].astype(int))

# Save the imputed dataset
df_clean.to_csv("data/imputed_dataset.csv", index=False)

# Display the fully imputed dataset
print("Imputation completed! The dataset has been saved as 'imputed_dataset.csv'.")
